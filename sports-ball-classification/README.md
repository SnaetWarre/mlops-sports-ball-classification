# Sports Ball Classification - MLOps Project

An end-to-end MLOps project for classifying sports balls using Azure Machine Learning, FastAPI, Docker, and Kubernetes.

## ğŸ€ Project Overview

This project implements a complete MLOps pipeline for classifying 15 different types of sports balls using a Convolutional Neural Network (CNN). The system includes:

- **Azure ML Pipeline**: Automated training pipeline with data preprocessing, model training, and registration
- **FastAPI REST API**: Production-ready API for inference with database integration
- **Docker & Kubernetes**: Containerized deployment with orchestration support
- **Persistent Storage**: PostgreSQL/SQLite database for storing prediction history

## ğŸ“Š Supported Ball Categories

| Category | Category | Category |
|----------|----------|----------|
| ğŸˆ american_football | âš¾ baseball | ğŸ€ basketball |
| ğŸ± billiard_ball | ğŸ³ bowling_ball | ğŸ cricket_ball |
| âš½ football | â›³ golf_ball | ğŸ‘ hockey_ball |
| ğŸ¥… hockey_puck | ğŸ‰ rugby_ball | ğŸ¸ shuttlecock |
| ğŸ“ table_tennis_ball | ğŸ¾ tennis_ball | ğŸ volleyball |

## ğŸ“ Project Structure

```
sports-ball-classification/
â”œâ”€â”€ components/                 # Azure ML pipeline components
â”‚   â”œâ”€â”€ dataprep/              # Image preprocessing & train-test split
â”‚   â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â”‚   â”œâ”€â”€ dataprep.py    # Image resizing script
â”‚   â”‚   â”‚   â””â”€â”€ traintestsplit.py
â”‚   â”‚   â”œâ”€â”€ conda.yaml
â”‚   â”‚   â”œâ”€â”€ dataprep.yaml
â”‚   â”‚   â””â”€â”€ data_split.yaml
â”‚   â”œâ”€â”€ training/              # CNN model training
â”‚   â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py       # Training script
â”‚   â”‚   â”‚   â””â”€â”€ utils.py       # Model architecture & utilities
â”‚   â”‚   â”œâ”€â”€ conda.yaml
â”‚   â”‚   â””â”€â”€ training.yaml
â”‚   â””â”€â”€ register/              # Model registration
â”‚       â”œâ”€â”€ code/
â”‚       â”‚   â””â”€â”€ register.py
â”‚       â”œâ”€â”€ conda.yaml
â”‚       â”œâ”€â”€ environment.yaml
â”‚       â””â”€â”€ register.yaml
â”œâ”€â”€ environment/               # Azure ML environment configs
â”‚   â”œâ”€â”€ compute-cluster.yaml
â”‚   â”œâ”€â”€ preprocessing.yaml
â”‚   â””â”€â”€ training.yaml
â”œâ”€â”€ inference/                 # FastAPI application
â”‚   â”œâ”€â”€ main.py               # API with database integration
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ kubernetes/                # K8s deployment manifests
â”‚   â””â”€â”€ deployment.yaml
â”œâ”€â”€ pipelines/                 # Azure ML pipeline definitions
â”‚   â””â”€â”€ sports-ball-classification.yaml
â”œâ”€â”€ setup_azure.sh            # Azure setup helper script
â””â”€â”€ README.md                 # This file
```

## ğŸš€ Quick Start

### Prerequisites

- Azure CLI with ML extension (`az extension add -n ml`)
- Docker & Docker Compose
- Python 3.10+
- kubectl (for Kubernetes deployment)

### 1. Azure ML Setup

```bash
# Login to Azure
az login

# Create resource group
az group create --name mlops-examen-rg --location westeurope

# Create ML workspace
az ml workspace create --name mlops-sports-ball-ws --resource-group mlops-examen-rg

# Set defaults
az configure --defaults group=mlops-examen-rg workspace=mlops-sports-ball-ws
```

### 2. Create Compute & Environments

```bash
# Create compute cluster
az ml compute create -f environment/compute-cluster.yaml

# Create environments
az ml environment create -f environment/preprocessing.yaml
az ml environment create -f environment/training.yaml
az ml environment create -f components/register/environment.yaml
```

### 3. Register Components

```bash
az ml component create -f components/dataprep/dataprep.yaml
az ml component create -f components/dataprep/data_split.yaml
az ml component create -f components/training/training.yaml
az ml component create -f components/register/register.yaml
```

### 4. Upload Dataset

```bash
# Upload each ball category
for ball in american_football baseball basketball billiard_ball bowling_ball cricket_ball football golf_ball hockey_ball hockey_puck rugby_ball shuttlecock table_tennis_ball tennis_ball volleyball; do
    az ml data create --name $ball --version 1 --path ../data/$ball --type uri_folder
done
```

### 5. Run Training Pipeline

```bash
az ml job create -f pipelines/sports-ball-classification.yaml
```

### 6. Deploy API

```bash
cd inference

# Using Docker Compose
docker-compose up -d

# Or using Docker directly
docker build -t sports-ball-api .
docker run -p 8000:8000 sports-ball-api
```

## ğŸ“¡ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Health check and API info |
| `/predict` | POST | Upload image for classification |
| `/predictions` | GET | Get prediction history |
| `/predictions/{id}` | GET | Get specific prediction |
| `/stats` | GET | Get prediction statistics |
| `/categories` | GET | List supported categories |

### Example: Classify an Image

```bash
curl -X POST "http://localhost:8000/predict" \
  -F "img=@tennis_ball.jpg"
```

Response:
```json
{
  "id": 1,
  "predicted_label": "tennis_ball",
  "confidence": 0.97,
  "all_scores": {...},
  "created_at": "2024-01-15T10:30:00Z"
}
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Azure Machine Learning                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ DataPrep â”‚ â†’ â”‚  Split   â”‚ â†’ â”‚ Training â”‚ â†’ â”‚ Register Model   â”‚  â”‚
â”‚  â”‚ (resize) â”‚   â”‚(train/   â”‚   â”‚  (CNN)   â”‚   â”‚ (to Azure ML)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  test)   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                              Model Download
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Docker / Kubernetes                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                        FastAPI                                  â”‚ â”‚
â”‚  â”‚  POST /predict â†’ CNN Inference â†’ Store in DB â†’ Return Result   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                â”‚                                     â”‚
â”‚                                â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                   PostgreSQL / SQLite                           â”‚ â”‚
â”‚  â”‚              Store prediction history & stats                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `MODEL_PATH` | Path to trained model | `./model.keras` |
| `DATABASE_URL` | Database connection string | `sqlite:///./predictions.db` |
| `PORT` | API port | `8000` |

## ğŸ“ Model Details

- **Architecture**: CNN with 3 convolutional blocks (32â†’64â†’128 filters)
- **Input Size**: 64x64 RGB images
- **Output**: 15-class softmax
- **Optimizer**: SGD with exponential decay learning rate
- **Data Augmentation**: Rotation, shifts, shear, zoom, horizontal flip

## ğŸ§¹ Cleanup

Don't forget to delete Azure resources when done to save costs:

```bash
az group delete --name mlops-examen-rg --yes --no-wait
```

## ğŸ“„ License

This project is part of an MLOps exam assignment for Howest.
