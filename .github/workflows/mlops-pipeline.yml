# Trigger rebuild - v2
name: ğŸ€ MLOps Sports Ball Classification

on:
  workflow_dispatch:
    inputs:
      action:
        description: "Action to perform"
        required: true
        default: "full-pipeline"
        type: choice
        options:
          - full-pipeline
          - train-only
          - download-model
          - deploy-inference
          - cleanup
      epochs:
        description: "Number of training epochs"
        required: false
        default: "10"
        type: string
      wait_for_completion:
        description: "Wait for training to complete before downloading model"
        required: false
        default: true
        type: boolean

  push:
    branches:
      - master
      - main
    paths:
      - "sports-ball-classification/**"
      - "data/**"

env:
  RESOURCE_GROUP: mlops-examen-rg
  WORKSPACE_NAME: mlops-sports-ball-ws
  LOCATION: westeurope
  COMPUTE_CLUSTER_NAME: sports-ball-cluster
  MODEL_NAME: sports-ball-cnn

jobs:
  # ============================================================================
  # Stage 1: Azure Infrastructure Setup
  # ============================================================================
  setup-azure:
    name: ğŸ—ï¸ Setup Azure Infrastructure
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.action == 'full-pipeline' || github.event.inputs.action == 'train-only' || github.event.inputs.action == '' }}

    outputs:
      infrastructure_ready: ${{ steps.verify.outputs.ready }}
      component_version: ${{ steps.register-components.outputs.component_version }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Install Azure ML CLI extension
        run: |
          az extension add -n ml -y
          az extension update -n ml

      - name: Create/Verify Resource Group
        run: |
          echo "ğŸ” Checking resource group..."
          if az group show --name ${{ env.RESOURCE_GROUP }} &>/dev/null; then
            echo "âœ… Resource group '${{ env.RESOURCE_GROUP }}' exists"
          else
            echo "ğŸ”¨ Creating resource group..."
            az group create --name ${{ env.RESOURCE_GROUP }} --location ${{ env.LOCATION }}
            echo "âœ… Resource group created"
          fi

      - name: Create/Verify Azure ML Workspace
        run: |
          echo "ğŸ” Checking workspace..."
          if az ml workspace show --name ${{ env.WORKSPACE_NAME }} --resource-group ${{ env.RESOURCE_GROUP }} &>/dev/null; then
            echo "âœ… Workspace '${{ env.WORKSPACE_NAME }}' exists"
          else
            echo "ğŸ”¨ Creating workspace (this takes a few minutes)..."
            az ml workspace create \
              --name ${{ env.WORKSPACE_NAME }} \
              --resource-group ${{ env.RESOURCE_GROUP }} \
              --location ${{ env.LOCATION }}
            echo "âœ… Workspace created"
          fi

      - name: Set Azure ML defaults
        run: |
          az configure --defaults group=${{ env.RESOURCE_GROUP }} workspace=${{ env.WORKSPACE_NAME }}

      - name: Create/Verify Compute Cluster
        working-directory: sports-ball-classification
        run: |
          echo "ğŸ” Checking compute cluster..."
          if az ml compute show --name ${{ env.COMPUTE_CLUSTER_NAME }} &>/dev/null; then
            echo "âœ… Compute cluster '${{ env.COMPUTE_CLUSTER_NAME }}' exists"
          else
            echo "ğŸ”¨ Creating compute cluster..."
            az ml compute create -f environment/compute-cluster.yaml
            echo "âœ… Compute cluster created"
          fi

      - name: Grant Compute Identity Model Registration Permissions
        run: |
          echo "ğŸ” Granting compute cluster identity permissions to register models..."

          # Get the workspace resource ID
          WORKSPACE_ID=$(az ml workspace show \
            --name ${{ env.WORKSPACE_NAME }} \
            --resource-group ${{ env.RESOURCE_GROUP }} \
            --query id -o tsv)

          # Get the compute cluster's managed identity principal ID
          IDENTITY_PRINCIPAL_ID=$(az ml compute show \
            --name ${{ env.COMPUTE_CLUSTER_NAME }} \
            --resource-group ${{ env.RESOURCE_GROUP }} \
            --workspace-name ${{ env.WORKSPACE_NAME }} \
            --query identity.principal_id -o tsv 2>/dev/null || echo "")

          if [ -z "$IDENTITY_PRINCIPAL_ID" ] || [ "$IDENTITY_PRINCIPAL_ID" == "null" ]; then
            echo "âš ï¸ Compute cluster does not have a system-assigned identity or it's not available yet"
            echo "   The model registration step may fail. Consider enabling system-assigned identity on the cluster."
          else
            echo "ğŸ“Œ Compute identity principal ID: $IDENTITY_PRINCIPAL_ID"
            echo "ğŸ“Œ Workspace ID: $WORKSPACE_ID"

            # Check if AzureML Data Scientist role assignment already exists
            # This role is required for ML data-plane operations (model registration, etc.)
            EXISTING_ROLE=$(az role assignment list \
              --assignee "$IDENTITY_PRINCIPAL_ID" \
              --scope "$WORKSPACE_ID" \
              --role "AzureML Data Scientist" \
              --query "[0].id" -o tsv 2>/dev/null || echo "")

            if [ -n "$EXISTING_ROLE" ]; then
              echo "âœ… AzureML Data Scientist role already assigned to compute identity"
            else
              echo "ğŸ”¨ Assigning AzureML Data Scientist role to compute identity..."
              az role assignment create \
                --assignee-object-id "$IDENTITY_PRINCIPAL_ID" \
                --assignee-principal-type ServicePrincipal \
                --role "AzureML Data Scientist" \
                --scope "$WORKSPACE_ID" || echo "âš ï¸ Role assignment failed (may already exist or lack permissions)"
              echo "âœ… AzureML Data Scientist role assignment complete"
            fi
          fi

      - name: Create/Verify Environments
        working-directory: sports-ball-classification
        run: |
          echo "ğŸŒ Setting up ML environments..."

          # Preprocessing environment
          if az ml environment show --name aml-preprocessing-cli --version 0.1.0 &>/dev/null 2>&1; then
            echo "âœ… Preprocessing environment exists"
          else
            echo "ğŸ”¨ Creating preprocessing environment..."
            az ml environment create -f environment/preprocessing.yaml || echo "âš ï¸ May already exist"
          fi

          # Training environment
          if az ml environment show --name aml-training-cli --version 0.1.0 &>/dev/null 2>&1; then
            echo "âœ… Training environment exists"
          else
            echo "ğŸ”¨ Creating training environment..."
            az ml environment create -f environment/training.yaml || echo "âš ï¸ May already exist"
          fi

          # Register environment - version 1.0.0 with Azure ML SDK (no azure-cli dependency)
          # Always recreate to ensure latest version is used
          echo "ğŸ”¨ Creating/updating register environment v1.0.0..."
          az ml environment create -f components/register/environment.yaml || echo "âš ï¸ May already exist"

          echo "âœ… All environments ready"

      - name: Register ML Components
        id: register-components
        working-directory: sports-ball-classification
        run: |
          echo "ğŸ§© Registering ML components..."

          # Generate a unique version based on run number
          VERSION="1.0.${{ github.run_number }}"
          echo "ğŸ“Œ Using component version: $VERSION"

          # Register components - create new versions each time to avoid immutability issues
          echo "ğŸ”¨ Registering data_prep_image_resize_cli..."
          az ml component create -f components/dataprep/dataprep.yaml --set version="$VERSION" || echo "âš ï¸ May already exist"

          echo "ğŸ”¨ Registering data_split_cli..."
          az ml component create -f components/dataprep/data_split.yaml --set version="$VERSION" || echo "âš ï¸ May already exist"

          echo "ğŸ”¨ Registering training_cli..."
          az ml component create -f components/training/training.yaml --set version="$VERSION" || echo "âš ï¸ May already exist"

          echo "ğŸ”¨ Registering register_model_cli..."
          az ml component create -f components/register/register.yaml --set version="$VERSION" || echo "âš ï¸ May already exist"

          echo "âœ… All components registered with version $VERSION"
          echo "component_version=$VERSION" >> $GITHUB_OUTPUT

      - name: Upload Training Datasets
        run: |
          echo "ğŸ“ Uploading datasets to Azure ML..."

          BALL_TYPES=(
            "american_football" "baseball" "basketball" "billiard_ball"
            "bowling_ball" "cricket_ball" "football" "golf_ball"
            "hockey_ball" "hockey_puck" "rugby_ball" "shuttlecock"
            "table_tennis_ball" "tennis_ball" "volleyball"
          )

          FAILED=0
          for ball in "${BALL_TYPES[@]}"; do
            if az ml data show --name "$ball" --version 1 &>/dev/null; then
              echo "âœ… '$ball' already registered in Azure ML"
            else
              if [ -d "data/$ball" ]; then
                # Check if directory has files
                FILE_COUNT=$(find "data/$ball" -type f \( -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" \) | wc -l)
                if [ "$FILE_COUNT" -gt 0 ]; then
                  echo "ğŸ”¨ Uploading '$ball' ($FILE_COUNT images)..."
                  if az ml data create --name "$ball" --version 1 --path "data/$ball" --type uri_folder; then
                    echo "âœ… '$ball' uploaded successfully"
                  else
                    echo "âŒ Failed to upload '$ball'"
                    FAILED=1
                  fi
                else
                  echo "âš ï¸ Warning: 'data/$ball' exists but contains no images!"
                  echo "   Make sure image files are committed to the repository."
                  FAILED=1
                fi
              else
                echo "âŒ Error: Directory 'data/$ball' not found!"
                FAILED=1
              fi
            fi
          done

          if [ "$FAILED" -eq 1 ]; then
            echo ""
            echo "âŒ Some datasets failed to upload. Check the logs above."
            echo "   Tip: Make sure image files are not excluded in .gitignore"
            exit 1
          fi

          echo "âœ… All datasets uploaded successfully"

      - name: Verify Infrastructure
        id: verify
        run: |
          echo "ğŸ” Verifying infrastructure..."
          echo "ready=true" >> $GITHUB_OUTPUT
          echo "âœ… Azure infrastructure is ready!"

  # ============================================================================
  # Stage 2: Run Training Pipeline
  # ============================================================================
  train-model:
    name: ğŸš€ Train Model on Azure ML
    runs-on: ubuntu-latest
    needs: setup-azure
    if: ${{ (github.event.inputs.action == 'full-pipeline' || github.event.inputs.action == 'train-only' || github.event.inputs.action == '') && needs.setup-azure.outputs.infrastructure_ready == 'true' }}

    outputs:
      job_name: ${{ steps.submit.outputs.job_name }}
      training_completed: ${{ steps.wait.outputs.completed }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Setup Azure ML CLI
        run: |
          az extension add -n ml -y
          az configure --defaults group=${{ env.RESOURCE_GROUP }} workspace=${{ env.WORKSPACE_NAME }}

      - name: Verify Data Assets Exist
        run: |
          echo "ğŸ” Verifying data assets are registered in Azure ML..."

          BALL_TYPES=(
            "american_football" "baseball" "basketball" "billiard_ball"
            "bowling_ball" "cricket_ball" "football" "golf_ball"
            "hockey_ball" "hockey_puck" "rugby_ball" "shuttlecock"
            "table_tennis_ball" "tennis_ball" "volleyball"
          )

          MISSING=0
          for ball in "${BALL_TYPES[@]}"; do
            if az ml data show --name "$ball" --version 1 &>/dev/null; then
              echo "âœ… $ball:1 exists"
            else
              echo "âŒ $ball:1 NOT FOUND"
              MISSING=1
            fi
          done

          if [ "$MISSING" -eq 1 ]; then
            echo ""
            echo "âŒ Some data assets are missing! Please run the setup-azure job first."
            exit 1
          fi

          echo "âœ… All data assets verified"

      - name: Submit Training Pipeline
        id: submit
        working-directory: sports-ball-classification
        run: |
          echo "ğŸš€ Submitting training pipeline..."

          # Get the component version from the previous step
          COMP_VERSION="${{ needs.setup-azure.outputs.component_version || '1.0.0' }}"
          echo "ğŸ“Œ Using component version: $COMP_VERSION"

          JOB_NAME=$(az ml job create \
            -f pipelines/sports-ball-classification.yaml \
            --set inputs.epochs=${{ github.event.inputs.epochs || '10' }} \
            --query name -o tsv)

          echo "job_name=$JOB_NAME" >> $GITHUB_OUTPUT

          echo ""
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘           ğŸš€ Training Pipeline Submitted!                   â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "Job Name: $JOB_NAME"
          echo "Epochs: ${{ github.event.inputs.epochs || '10' }}"

      - name: Wait for Training Completion
        id: wait
        if: ${{ github.event.inputs.wait_for_completion == 'true' || github.event.inputs.wait_for_completion == '' }}
        run: |
          echo "â³ Waiting for training to complete..."
          echo "   This may take 15-30 minutes depending on dataset size and epochs."
          echo ""

          JOB_NAME="${{ steps.submit.outputs.job_name }}"

          # Stream logs and wait for completion
          az ml job stream --name $JOB_NAME || true

          # Check final status
          STATUS=$(az ml job show --name $JOB_NAME --query status -o tsv)
          echo ""
          echo "Final Status: $STATUS"

          if [ "$STATUS" == "Completed" ]; then
            echo "completed=true" >> $GITHUB_OUTPUT
            echo "âœ… Training completed successfully!"
          else
            echo "completed=false" >> $GITHUB_OUTPUT
            echo "âŒ Training status: $STATUS"
            exit 1
          fi

  # ============================================================================
  # Stage 3: Download Model to Local Machine
  # ============================================================================
  download-model:
    name: ğŸ“¥ Download Trained Model
    runs-on: self-hosted
    needs: train-model
    if: |
      always() &&
      (github.event.inputs.action == 'full-pipeline' || github.event.inputs.action == 'download-model' || github.event.inputs.action == '') &&
      (needs.train-model.outputs.training_completed == 'true' || github.event.inputs.action == 'download-model')

    outputs:
      model_downloaded: ${{ steps.download.outputs.success }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Display Runner Info
        run: |
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘           ğŸ“¥ Downloading Model to Local Machine             â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ğŸ–¥ï¸  Host: $(hostname)"
          echo "ğŸ“ Working directory: $(pwd)"

      - name: Azure Login (CLI)
        run: |
          echo "ğŸ” Logging into Azure..."
          # Parse credentials from secret
          echo '${{ secrets.AZURE_CREDENTIALS }}' > /tmp/azure_creds.json

          CLIENT_ID=$(cat /tmp/azure_creds.json | python3 -c "import sys, json; print(json.load(sys.stdin)['clientId'])")
          CLIENT_SECRET=$(cat /tmp/azure_creds.json | python3 -c "import sys, json; print(json.load(sys.stdin)['clientSecret'])")
          TENANT_ID=$(cat /tmp/azure_creds.json | python3 -c "import sys, json; print(json.load(sys.stdin)['tenantId'])")

          az login --service-principal -u "$CLIENT_ID" -p "$CLIENT_SECRET" --tenant "$TENANT_ID"
          rm /tmp/azure_creds.json

          az extension add -n ml -y 2>/dev/null || true
          az configure --defaults group=${{ env.RESOURCE_GROUP }} workspace=${{ env.WORKSPACE_NAME }}
          echo "âœ… Logged in successfully"

      - name: Get Latest Model Version
        id: get-model
        run: |
          echo "ğŸ” Finding latest model version..."

          # Get the latest version of the model
          MODEL_VERSION=$(az ml model list --name ${{ env.MODEL_NAME }} --query "[0].version" -o tsv 2>/dev/null || echo "")

          if [ -z "$MODEL_VERSION" ]; then
            echo "âš ï¸ No model found with name '${{ env.MODEL_NAME }}'"
            echo "   Make sure training has completed successfully."
            exit 1
          fi

          echo "model_version=$MODEL_VERSION" >> $GITHUB_OUTPUT
          echo "âœ… Found model version: $MODEL_VERSION"

      - name: Download Model
        id: download
        run: |
          echo "ğŸ“¥ Downloading model..."

          MODEL_VERSION="${{ steps.get-model.outputs.model_version }}"
          MODEL_DIR="sports-ball-classification/inference/model/${{ env.MODEL_NAME }}"

          # Create model directory
          mkdir -p "$MODEL_DIR"

          # Download the model
          az ml model download \
            --name ${{ env.MODEL_NAME }} \
            --version $MODEL_VERSION \
            --download-path "$MODEL_DIR"

          echo ""
          echo "ğŸ“ Downloaded model contents:"
          ls -la "$MODEL_DIR"
          find "$MODEL_DIR" -type f

          # Move model files to expected location if nested
          if [ -d "$MODEL_DIR/${{ env.MODEL_NAME }}" ]; then
            mv "$MODEL_DIR/${{ env.MODEL_NAME }}"/* "$MODEL_DIR/" 2>/dev/null || true
            rmdir "$MODEL_DIR/${{ env.MODEL_NAME }}" 2>/dev/null || true
          fi

          echo ""
          echo "success=true" >> $GITHUB_OUTPUT
          echo "âœ… Model downloaded to $MODEL_DIR"

      - name: Verify Model Files
        run: |
          MODEL_DIR="sports-ball-classification/inference/model/${{ env.MODEL_NAME }}"

          echo "ğŸ” Verifying model files..."

          if [ -f "$MODEL_DIR/model.keras" ] || [ -f "$MODEL_DIR/saved_model.pb" ] || [ -d "$MODEL_DIR/variables" ]; then
            echo "âœ… Model files verified!"
            ls -la "$MODEL_DIR"
          else
            echo "ğŸ“ Model directory contents:"
            find "$MODEL_DIR" -type f 2>/dev/null || echo "No files found"
            echo ""
            echo "âš ï¸ Expected model format not found, but files may still be usable"
          fi

  # ============================================================================
  # Stage 4: Deploy Inference API (Self-Hosted Runner)
  # ============================================================================
  deploy-inference:
    name: ğŸ³ Deploy Inference API
    runs-on: self-hosted
    needs: download-model
    if: |
      always() &&
      (github.event.inputs.action == 'full-pipeline' || github.event.inputs.action == 'deploy-inference' || github.event.inputs.action == '') &&
      (needs.download-model.outputs.model_downloaded == 'true' || github.event.inputs.action == 'deploy-inference')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Display Deployment Info
        run: |
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘        ğŸ³ Deploying Sports Ball Classification API         â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ğŸ–¥ï¸  Host: $(hostname)"
          echo "ğŸ“ Working directory: $(pwd)"

      - name: Stop Existing Containers
        working-directory: sports-ball-classification/inference
        run: |
          echo "ğŸ›‘ Stopping existing containers..."
          docker-compose down 2>/dev/null || true
          echo "âœ… Containers stopped"

      - name: Build Docker Images
        working-directory: sports-ball-classification/inference
        run: |
          echo "ğŸ”¨ Building Docker images..."
          docker-compose build
          echo "âœ… Build complete"

      - name: Start Containers
        working-directory: sports-ball-classification/inference
        run: |
          echo "ğŸš€ Starting containers..."
          docker-compose up -d
          echo "âœ… Containers started"

      - name: Wait for Services
        run: |
          echo "â³ Waiting for services to start..."
          sleep 15

      - name: Health Check
        run: |
          echo "ğŸ¥ Running health check..."
          for i in {1..12}; do
            if curl -s http://localhost:8000/health | grep -q "healthy"; then
              echo "âœ… API is healthy!"
              break
            fi
            echo "   Waiting for API... (attempt $i/12)"
            sleep 5
          done

      - name: Test Prediction
        run: |
          echo "ğŸ§ª Testing prediction endpoint..."

          SAMPLE_IMAGE=$(find data -name "*.jpg" 2>/dev/null | head -1)
          if [ -n "$SAMPLE_IMAGE" ]; then
            echo "   Using sample image: $SAMPLE_IMAGE"
            RESULT=$(curl -s -X POST "http://localhost:8000/predict" \
              -H "accept: application/json" \
              -H "Content-Type: multipart/form-data" \
              -F "img=@$SAMPLE_IMAGE")
            echo "   Result: $RESULT"
          fi

      - name: Deployment Summary
        working-directory: sports-ball-classification/inference
        run: |
          echo ""
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘           ğŸ‰ Deployment Complete!                           â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ğŸ“¡ API Endpoints:"
          echo "   â€¢ Swagger UI: http://localhost:8000/docs"
          echo "   â€¢ Health:     http://localhost:8000/health"
          echo "   â€¢ Predict:    http://localhost:8000/predict"
          echo "   â€¢ Categories: http://localhost:8000/categories"
          echo "   â€¢ Stats:      http://localhost:8000/stats"
          echo ""
          echo "ğŸ“Š Container status:"
          docker-compose ps

  # ============================================================================
  # Cleanup Azure Resources
  # ============================================================================
  cleanup:
    name: ğŸ—‘ï¸ Cleanup Azure Resources
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.action == 'cleanup' }}

    steps:
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Delete Resource Group
        run: |
          echo "ğŸ—‘ï¸ Deleting resource group '${{ env.RESOURCE_GROUP }}'..."
          echo "âš ï¸ This will delete ALL resources in the group!"

          az group delete --name ${{ env.RESOURCE_GROUP }} --yes --no-wait

          echo "âœ… Deletion initiated (running in background)"

  # ============================================================================
  # Pipeline Summary
  # ============================================================================
  summary:
    name: ğŸ“‹ Pipeline Summary
    runs-on: ubuntu-latest
    needs: [setup-azure, train-model, download-model, deploy-inference]
    if: always() && github.event.inputs.action != 'cleanup'

    steps:
      - name: Print Summary
        run: |
          echo ""
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘     ğŸ€ Sports Ball Classification - Pipeline Summary ğŸ€     â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ğŸ“Š Stage Results:"
          echo "   1ï¸âƒ£  Azure Setup:     ${{ needs.setup-azure.result || 'skipped' }}"
          echo "   2ï¸âƒ£  Model Training:  ${{ needs.train-model.result || 'skipped' }}"
          echo "   3ï¸âƒ£  Model Download:  ${{ needs.download-model.result || 'skipped' }}"
          echo "   4ï¸âƒ£  API Deployment:  ${{ needs.deploy-inference.result || 'skipped' }}"
          echo ""

          if [ "${{ needs.train-model.outputs.job_name }}" != "" ]; then
            echo "ğŸ”¬ Training Job: ${{ needs.train-model.outputs.job_name }}"
            echo ""
          fi

          echo "ğŸ”— Azure ML Studio: https://ml.azure.com"
          echo "ğŸ“¡ Local API: http://localhost:8000/docs"
          echo ""
