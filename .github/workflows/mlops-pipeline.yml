# Trigger rebuild - v2
name: ğŸ€ MLOps Sports Ball Classification

on:
  workflow_dispatch:
    inputs:
      action:
        description: "Action to perform"
        required: true
        default: "full-pipeline"
        type: choice
        options:
          - full-pipeline
          - train-only
          - download-model
          - deploy-inference
          - cleanup
      epochs:
        description: "Number of training epochs"
        required: false
        default: "30"
        type: string
      wait_for_completion:
        description: "Wait for training to complete before downloading model"
        required: false
        default: true
        type: boolean

  push:
    branches:
      - master
      - main
    paths:
      - "sports-ball-classification/**"
      - "data/**"
      - ".github/workflows/**"
env:
  RESOURCE_GROUP: mlops-examen-rg
  WORKSPACE_NAME: mlops-sports-ball-ws
  LOCATION: westeurope
  COMPUTE_CLUSTER_NAME: sports-ball-cluster
  MODEL_NAME: sports-ball-classification

jobs:
  # ============================================================================
  # Stage 0: Configure Permissions (Self-Hosted)
  # ============================================================================
  configure-permissions:
    name: ğŸ” Configure Azure Permissions
    runs-on: self-hosted
    if: ${{ github.event.inputs.action == 'full-pipeline' || github.event.inputs.action == 'train-only' || github.event.inputs.action == '' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Azure Permissions
        env:
          AZURE_CREDENTIALS: ${{ secrets.AZURE_CREDENTIALS }}
        run: |
          echo "ğŸ”§ Running setup-azure-permissions.sh using runner's identity..."
          chmod +x scripts/setup-azure-permissions.sh
          # This will use the runner's existing login (e.g. your personal account)
          # to grant permissions to the Service Principal defined in secrets.
          ./scripts/setup-azure-permissions.sh --auto-approve

  # ============================================================================
  # Stage 1: Azure Infrastructure Setup
  # ============================================================================
  setup-azure:
    name: ğŸ—ï¸ Setup Azure Infrastructure
    runs-on: ubuntu-latest
    needs: configure-permissions
    if: ${{ github.event.inputs.action == 'full-pipeline' || github.event.inputs.action == 'train-only' || github.event.inputs.action == '' }}

    outputs:
      infrastructure_ready: ${{ steps.verify.outputs.ready }}
      component_version: ${{ steps.register-components.outputs.component_version }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Install Azure ML CLI extension
        run: |
          az extension add -n ml -y
          az extension update -n ml

      - name: Create/Verify Resource Group
        run: |
          echo "ğŸ” Checking resource group..."
          if az group show --name ${{ env.RESOURCE_GROUP }} &>/dev/null; then
            echo "âœ… Resource group '${{ env.RESOURCE_GROUP }}' exists"
          else
            echo "ğŸ”¨ Creating resource group..."
            az group create --name ${{ env.RESOURCE_GROUP }} --location ${{ env.LOCATION }}
            echo "âœ… Resource group created"
          fi

      - name: Create/Verify Azure ML Workspace
        run: |
          echo "ğŸ” Checking workspace..."
          if az ml workspace show --name ${{ env.WORKSPACE_NAME }} --resource-group ${{ env.RESOURCE_GROUP }} &>/dev/null; then
            echo "âœ… Workspace '${{ env.WORKSPACE_NAME }}' exists"
          else
            echo "ğŸ”¨ Creating workspace (this takes a few minutes)..."
            az ml workspace create \
              --name ${{ env.WORKSPACE_NAME }} \
              --resource-group ${{ env.RESOURCE_GROUP }} \
              --location ${{ env.LOCATION }}
            echo "âœ… Workspace created"
          fi

      - name: Set Azure ML defaults
        run: |
          az configure --defaults group=${{ env.RESOURCE_GROUP }} workspace=${{ env.WORKSPACE_NAME }}

      - name: Create/Verify Compute Cluster
        working-directory: sports-ball-classification
        run: |
          echo "ğŸ” Checking compute cluster..."
          CLUSTER_EXISTS=false
          if az ml compute show --name ${{ env.COMPUTE_CLUSTER_NAME }} &>/dev/null; then
            echo "âœ… Compute cluster '${{ env.COMPUTE_CLUSTER_NAME }}' exists"
            CLUSTER_EXISTS=true
          else
            echo "ğŸ”¨ Creating compute cluster..."
            az ml compute create -f environment/compute-cluster.yaml
            echo "âœ… Compute cluster created"
          fi

          # If cluster was just created, wait for identity to be provisioned
          if [ "$CLUSTER_EXISTS" = false ]; then
            echo "â³ Waiting for compute cluster identity to be provisioned..."
            sleep 30
          fi

      - name: Grant Compute Identity Model Registration Permissions
        run: |
          echo "ğŸ” Granting compute cluster identity permissions to register models..."

          # Get the workspace resource ID
          WORKSPACE_ID=$(az ml workspace show \
            --name ${{ env.WORKSPACE_NAME }} \
            --resource-group ${{ env.RESOURCE_GROUP }} \
            --query id -o tsv)

          # Wait for the compute cluster's managed identity to become available (retry loop)
          echo "ğŸ” Getting compute cluster managed identity..."
          IDENTITY_PRINCIPAL_ID=""
          for i in {1..12}; do
            IDENTITY_PRINCIPAL_ID=$(az ml compute show \
              --name ${{ env.COMPUTE_CLUSTER_NAME }} \
              --resource-group ${{ env.RESOURCE_GROUP }} \
              --workspace-name ${{ env.WORKSPACE_NAME }} \
              --query identity.principal_id -o tsv 2>/dev/null || echo "")

            if [ -n "$IDENTITY_PRINCIPAL_ID" ] && [ "$IDENTITY_PRINCIPAL_ID" != "null" ]; then
              echo "âœ… Found identity principal ID: $IDENTITY_PRINCIPAL_ID"
              break
            fi

            echo "   Waiting for identity to be available... (attempt $i/12)"
            sleep 10
          done

          if [ -z "$IDENTITY_PRINCIPAL_ID" ] || [ "$IDENTITY_PRINCIPAL_ID" == "null" ]; then
            echo "âŒ ERROR: Compute cluster managed identity not available after 2 minutes"
            echo "   Please ensure the compute cluster has system-assigned identity enabled."
            echo "   You may need to manually run:"
            echo "   az role assignment create --assignee-object-id <PRINCIPAL_ID> --assignee-principal-type ServicePrincipal --role 'AzureML Data Scientist' --scope '$WORKSPACE_ID'"
            exit 1
          fi

          echo "ğŸ“Œ Compute identity principal ID: $IDENTITY_PRINCIPAL_ID"
          echo "ğŸ“Œ Workspace ID: $WORKSPACE_ID"

          # Check if AzureML Data Scientist role assignment already exists
          EXISTING_ROLE=$(az role assignment list \
            --assignee "$IDENTITY_PRINCIPAL_ID" \
            --scope "$WORKSPACE_ID" \
            --role "AzureML Data Scientist" \
            --query "[0].id" -o tsv 2>/dev/null || echo "")

          if [ -n "$EXISTING_ROLE" ]; then
            echo "âœ… AzureML Data Scientist role already assigned to compute identity"
          else
            echo "ğŸ”¨ Assigning AzureML Data Scientist role to compute identity..."

            # Attempt role assignment with proper error handling
            if az role assignment create \
              --assignee-object-id "$IDENTITY_PRINCIPAL_ID" \
              --assignee-principal-type ServicePrincipal \
              --role "AzureML Data Scientist" \
              --scope "$WORKSPACE_ID" 2>&1; then
              echo "âœ… AzureML Data Scientist role assignment complete"
            else
              echo ""
              echo "âŒ ERROR: Role assignment failed!"
              echo ""
              echo "   This usually means the service principal (AZURE_CREDENTIALS) doesn't have"
              echo "   permission to assign roles. The service principal needs 'Owner' or"
              echo "   'User Access Administrator' role on the resource group."
              echo ""
              echo "   To fix this, run the following command with an Owner account:"
              echo ""
              echo "   az role assignment create \\"
              echo "     --assignee-object-id $IDENTITY_PRINCIPAL_ID \\"
              echo "     --assignee-principal-type ServicePrincipal \\"
              echo "     --role 'AzureML Data Scientist' \\"
              echo "     --scope '$WORKSPACE_ID'"
              echo ""
              exit 1
            fi
          fi

      - name: Create/Verify Environments
        working-directory: sports-ball-classification
        run: |
          echo "ğŸŒ Setting up ML environments..."

          # Preprocessing environment
          if az ml environment show --name aml-preprocessing-cli --version 0.1.0 &>/dev/null 2>&1; then
            echo "âœ… Preprocessing environment exists"
          else
            echo "ğŸ”¨ Creating preprocessing environment..."
            az ml environment create -f environment/preprocessing.yaml || echo "âš ï¸ May already exist"
          fi

          # Training environment
          if az ml environment show --name aml-training-cli --version 0.1.0 &>/dev/null 2>&1; then
            echo "âœ… Training environment exists"
          else
            echo "ğŸ”¨ Creating training environment..."
            az ml environment create -f environment/training.yaml || echo "âš ï¸ May already exist"
          fi

          # Register environment - version 1.0.0 with Azure ML SDK (no azure-cli dependency)
          # Always recreate to ensure latest version is used
          echo "ğŸ”¨ Creating/updating register environment v1.0.0..."
          az ml environment create -f components/register/environment.yaml || echo "âš ï¸ May already exist"

          echo "âœ… All environments ready"

      - name: Register ML Components
        id: register-components
        working-directory: sports-ball-classification
        run: |
          echo "ğŸ§© Registering ML components..."

          # Generate a unique version based on run number
          VERSION="1.0.${{ github.run_number }}"
          echo "ğŸ“Œ Using component version: $VERSION"

          # Register components - create new versions each time to avoid immutability issues
          echo "ğŸ”¨ Registering data_prep_image_resize_cli..."
          az ml component create -f components/dataprep/dataprep.yaml --set version="$VERSION" || echo "âš ï¸ May already exist"

          echo "ğŸ”¨ Registering data_split_cli..."
          az ml component create -f components/dataprep/data_split.yaml --set version="$VERSION" || echo "âš ï¸ May already exist"

          echo "ğŸ”¨ Registering training_cli..."
          az ml component create -f components/training/training.yaml --set version="$VERSION" || echo "âš ï¸ May already exist"

          echo "ğŸ”¨ Registering register_model_cli..."
          az ml component create -f components/register/register.yaml --set version="$VERSION" || echo "âš ï¸ May already exist"

          echo "âœ… All components registered with version $VERSION"
          echo "component_version=$VERSION" >> $GITHUB_OUTPUT

      - name: Upload Training Datasets
        run: |
          echo "ğŸ“ Uploading datasets to Azure ML..."

          BALL_TYPES=(
            "american_football" "baseball" "basketball" "billiard_ball"
            "bowling_ball" "cricket_ball" "football" "golf_ball"
            "hockey_ball" "hockey_puck" "rugby_ball" "shuttlecock"
            "table_tennis_ball" "tennis_ball" "volleyball"
          )

          FAILED=0
          for ball in "${BALL_TYPES[@]}"; do
            if az ml data show --name "$ball" --version 1 &>/dev/null; then
              echo "âœ… '$ball' already registered in Azure ML"
            else
              if [ -d "data/$ball" ]; then
                # Check if directory has files
                FILE_COUNT=$(find "data/$ball" -type f \( -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" \) | wc -l)
                if [ "$FILE_COUNT" -gt 0 ]; then
                  echo "ğŸ”¨ Uploading '$ball' ($FILE_COUNT images)..."
                  if az ml data create --name "$ball" --version 1 --path "data/$ball" --type uri_folder; then
                    echo "âœ… '$ball' uploaded successfully"
                  else
                    echo "âŒ Failed to upload '$ball'"
                    FAILED=1
                  fi
                else
                  echo "âš ï¸ Warning: 'data/$ball' exists but contains no images!"
                  echo "   Make sure image files are committed to the repository."
                  FAILED=1
                fi
              else
                echo "âŒ Error: Directory 'data/$ball' not found!"
                FAILED=1
              fi
            fi
          done

          if [ "$FAILED" -eq 1 ]; then
            echo ""
            echo "âŒ Some datasets failed to upload. Check the logs above."
            echo "   Tip: Make sure image files are not excluded in .gitignore"
            exit 1
          fi

          echo "âœ… All datasets uploaded successfully"

      - name: Verify Infrastructure
        id: verify
        run: |
          echo "ğŸ” Verifying infrastructure..."
          echo "ready=true" >> $GITHUB_OUTPUT
          echo "âœ… Azure infrastructure is ready!"

  # ============================================================================
  # Stage 2: Run Training Pipeline
  # ============================================================================
  train-model:
    name: ğŸš€ Train Model on Azure ML
    runs-on: ubuntu-latest
    needs: setup-azure
    if: ${{ (github.event.inputs.action == 'full-pipeline' || github.event.inputs.action == 'train-only' || github.event.inputs.action == '') && needs.setup-azure.outputs.infrastructure_ready == 'true' }}

    outputs:
      job_name: ${{ steps.submit.outputs.job_name }}
      training_completed: ${{ steps.wait.outputs.completed }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Setup Azure ML CLI
        run: |
          az extension add -n ml -y
          az configure --defaults group=${{ env.RESOURCE_GROUP }} workspace=${{ env.WORKSPACE_NAME }}

      - name: Verify Data Assets Exist
        run: |
          echo "ğŸ” Verifying data assets are registered in Azure ML..."

          BALL_TYPES=(
            "american_football" "baseball" "basketball" "billiard_ball"
            "bowling_ball" "cricket_ball" "football" "golf_ball"
            "hockey_ball" "hockey_puck" "rugby_ball" "shuttlecock"
            "table_tennis_ball" "tennis_ball" "volleyball"
          )

          MISSING=0
          for ball in "${BALL_TYPES[@]}"; do
            if az ml data show --name "$ball" --version 1 &>/dev/null; then
              echo "âœ… $ball:1 exists"
            else
              echo "âŒ $ball:1 NOT FOUND"
              MISSING=1
            fi
          done

          if [ "$MISSING" -eq 1 ]; then
            echo ""
            echo "âŒ Some data assets are missing! Please run the setup-azure job first."
            exit 1
          fi

          echo "âœ… All data assets verified"

      - name: Submit Training Pipeline
        id: submit
        working-directory: sports-ball-classification
        run: |
          echo "ğŸš€ Submitting training pipeline..."

          # Get the component version from the previous step
          COMP_VERSION="${{ needs.setup-azure.outputs.component_version || '1.0.0' }}"
          echo "ğŸ“Œ Using component version: $COMP_VERSION"

          JOB_NAME=$(az ml job create \
            -f pipelines/sports-ball-classification.yaml \
            --set inputs.epochs=${{ github.event.inputs.epochs || '30' }} \
            --query name -o tsv)

          echo "job_name=$JOB_NAME" >> $GITHUB_OUTPUT

          echo ""
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘           ğŸš€ Training Pipeline Submitted!                   â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "Job Name: $JOB_NAME"
          echo "Epochs: ${{ github.event.inputs.epochs || '30' }}"

      - name: Wait for Training Completion
        id: wait
        if: ${{ github.event.inputs.wait_for_completion == 'true' || github.event.inputs.wait_for_completion == '' }}
        run: |
          echo "â³ Waiting for training to complete..."
          echo "   This may take 15-30 minutes depending on dataset size and epochs."
          echo ""

          JOB_NAME="${{ steps.submit.outputs.job_name }}"

          # Stream logs and wait for completion
          az ml job stream --name $JOB_NAME || true

          # Check final status
          STATUS=$(az ml job show --name $JOB_NAME --query status -o tsv)
          echo ""
          echo "Final Status: $STATUS"

          if [ "$STATUS" == "Completed" ]; then
            echo "completed=true" >> $GITHUB_OUTPUT
            echo "âœ… Training completed successfully!"
          else
            echo "completed=false" >> $GITHUB_OUTPUT
            echo "âŒ Training status: $STATUS"
            exit 1
          fi

  # ============================================================================
  # Stage 3: Download Model to Local Machine
  # ============================================================================
  download-model:
    name: ğŸ“¥ Download Trained Model
    runs-on: self-hosted
    needs: train-model
    if: |
      always() &&
      (github.event.inputs.action == 'full-pipeline' || github.event.inputs.action == 'download-model' || github.event.inputs.action == '') &&
      (needs.train-model.outputs.training_completed == 'true' || github.event.inputs.action == 'download-model')

    outputs:
      model_downloaded: ${{ steps.download.outputs.success }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Display Runner Info
        run: |
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘           ğŸ“¥ Downloading Model to Local Machine             â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ğŸ–¥ï¸  Host: $(hostname)"
          echo "ğŸ“ Working directory: $(pwd)"

      - name: Azure Login (CLI)
        run: |
          echo "ğŸ” Logging into Azure..."
          # Parse credentials from secret
          echo '${{ secrets.AZURE_CREDENTIALS }}' > /tmp/azure_creds.json

          CLIENT_ID=$(cat /tmp/azure_creds.json | python3 -c "import sys, json; print(json.load(sys.stdin)['clientId'])")
          CLIENT_SECRET=$(cat /tmp/azure_creds.json | python3 -c "import sys, json; print(json.load(sys.stdin)['clientSecret'])")
          TENANT_ID=$(cat /tmp/azure_creds.json | python3 -c "import sys, json; print(json.load(sys.stdin)['tenantId'])")

          az login --service-principal -u "$CLIENT_ID" -p "$CLIENT_SECRET" --tenant "$TENANT_ID"
          rm /tmp/azure_creds.json

          az extension add -n ml -y 2>/dev/null || true
          az configure --defaults group=${{ env.RESOURCE_GROUP }} workspace=${{ env.WORKSPACE_NAME }}
          echo "âœ… Logged in successfully"

      - name: Get Latest Model Version
        id: get-model
        run: |
          echo "ğŸ” Finding latest model version..."

          # Get the latest version of the model
          MODEL_VERSION=$(az ml model list --name ${{ env.MODEL_NAME }} --query "[0].version" -o tsv 2>/dev/null || echo "")

          if [ -z "$MODEL_VERSION" ]; then
            echo "âš ï¸ No model found with name '${{ env.MODEL_NAME }}'"
            echo "   Make sure training has completed successfully."
            exit 1
          fi

          echo "model_version=$MODEL_VERSION" >> $GITHUB_OUTPUT
          echo "âœ… Found model version: $MODEL_VERSION"

      - name: Download Model
        id: download
        run: |
          echo "ğŸ“¥ Downloading model..."

          MODEL_VERSION="${{ steps.get-model.outputs.model_version }}"

          # Use a permanent location on the self-hosted runner (outside workspace)
          PERSISTENT_MODEL_DIR="$HOME/mlops-models/${{ env.MODEL_NAME }}"
          WORKSPACE_MODEL_DIR="sports-ball-classification/inference/model/${{ env.MODEL_NAME }}"
          TEMP_DOWNLOAD_DIR="/tmp/model-download-$$"

          # Create directories
          mkdir -p "$PERSISTENT_MODEL_DIR"
          mkdir -p "$WORKSPACE_MODEL_DIR"
          mkdir -p "$TEMP_DOWNLOAD_DIR"

          # Download the model to temp location first
          az ml model download \
            --name ${{ env.MODEL_NAME }} \
            --version $MODEL_VERSION \
            --download-path "$TEMP_DOWNLOAD_DIR"

          echo ""
          echo "ğŸ“ Downloaded model contents:"
          find "$TEMP_DOWNLOAD_DIR" -type f

          # Find the model.keras file and flatten the structure
          MODEL_FILE=$(find "$TEMP_DOWNLOAD_DIR" -name "model.keras" -type f | head -1)
          LABELS_FILE=$(find "$TEMP_DOWNLOAD_DIR" -name "labels.txt" -type f | head -1)

          if [ -n "$MODEL_FILE" ]; then
            echo "ğŸ“¦ Found model at: $MODEL_FILE"
            cp "$MODEL_FILE" "$PERSISTENT_MODEL_DIR/model.keras"
            cp "$MODEL_FILE" "$WORKSPACE_MODEL_DIR/model.keras"

            if [ -n "$LABELS_FILE" ]; then
              cp "$LABELS_FILE" "$PERSISTENT_MODEL_DIR/labels.txt"
              cp "$LABELS_FILE" "$WORKSPACE_MODEL_DIR/labels.txt"
            fi
          else
            # Fallback: copy everything
            cp -r "$TEMP_DOWNLOAD_DIR"/* "$PERSISTENT_MODEL_DIR/" 2>/dev/null || true
            cp -r "$TEMP_DOWNLOAD_DIR"/* "$WORKSPACE_MODEL_DIR/" 2>/dev/null || true
          fi

          # Cleanup temp directory
          rm -rf "$TEMP_DOWNLOAD_DIR"

          echo ""
          echo "ğŸ“ Persistent model location: $PERSISTENT_MODEL_DIR"
          ls -la "$PERSISTENT_MODEL_DIR"
          echo ""
          echo "ğŸ“ Workspace model location: $WORKSPACE_MODEL_DIR"
          ls -la "$WORKSPACE_MODEL_DIR"

          # Save the persistent path for the deploy job
          echo "persistent_model_dir=$PERSISTENT_MODEL_DIR" >> $GITHUB_OUTPUT
          echo "success=true" >> $GITHUB_OUTPUT
          echo "âœ… Model downloaded and stored in persistent location"

      - name: Verify Model Files
        run: |
          PERSISTENT_MODEL_DIR="$HOME/mlops-models/${{ env.MODEL_NAME }}"
          WORKSPACE_MODEL_DIR="sports-ball-classification/inference/model/${{ env.MODEL_NAME }}"

          echo "ğŸ” Verifying model files..."

          # Check persistent location
          if [ -f "$PERSISTENT_MODEL_DIR/model.keras" ]; then
            echo "âœ… Model verified in persistent location!"
            ls -la "$PERSISTENT_MODEL_DIR"
          else
            echo "âš ï¸ Model not found in persistent location: $PERSISTENT_MODEL_DIR"
          fi

          # Check workspace location
          if [ -f "$WORKSPACE_MODEL_DIR/model.keras" ]; then
            echo "âœ… Model verified in workspace location!"
            ls -la "$WORKSPACE_MODEL_DIR"
          else
            echo "âš ï¸ Model not found in workspace location: $WORKSPACE_MODEL_DIR"
          fi

  # ============================================================================
  # Stage 4: Deploy Inference API (Self-Hosted Runner)
  # ============================================================================
  deploy-inference:
    name: ğŸ³ Deploy Inference API
    runs-on: self-hosted
    needs: download-model
    if: |
      always() &&
      (github.event.inputs.action == 'full-pipeline' || github.event.inputs.action == 'deploy-inference' || github.event.inputs.action == '') &&
      (needs.download-model.outputs.model_downloaded == 'true' || github.event.inputs.action == 'deploy-inference')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Display Deployment Info
        run: |
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘        ğŸ³ Deploying Sports Ball Classification API         â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ğŸ–¥ï¸  Host: $(hostname)"
          echo "ğŸ“ Working directory: $(pwd)"

      - name: Azure Login (CLI)
        run: |
          echo "ğŸ” Logging into Azure..."
          # Parse credentials from secret
          echo '${{ secrets.AZURE_CREDENTIALS }}' > /tmp/azure_creds.json

          CLIENT_ID=$(cat /tmp/azure_creds.json | python3 -c "import sys, json; print(json.load(sys.stdin)['clientId'])")
          CLIENT_SECRET=$(cat /tmp/azure_creds.json | python3 -c "import sys, json; print(json.load(sys.stdin)['clientSecret'])")
          TENANT_ID=$(cat /tmp/azure_creds.json | python3 -c "import sys, json; print(json.load(sys.stdin)['tenantId'])")

          az login --service-principal -u "$CLIENT_ID" -p "$CLIENT_SECRET" --tenant "$TENANT_ID"
          rm /tmp/azure_creds.json

          az extension add -n ml -y 2>/dev/null || true
          az configure --defaults group=${{ env.RESOURCE_GROUP }} workspace=${{ env.WORKSPACE_NAME }}
          echo "âœ… Logged in successfully"

      - name: Restore Model from Persistent Storage
        run: |
          echo "ğŸ“¦ Restoring model from persistent storage..."

          PERSISTENT_MODEL_DIR="$HOME/mlops-models/${{ env.MODEL_NAME }}"
          WORKSPACE_MODEL_DIR="sports-ball-classification/inference/model/${{ env.MODEL_NAME }}"

          # Create workspace model directory
          mkdir -p "$WORKSPACE_MODEL_DIR"

          # Copy model from persistent location to workspace
          if [ -f "$PERSISTENT_MODEL_DIR/model.keras" ]; then
            cp "$PERSISTENT_MODEL_DIR/model.keras" "$WORKSPACE_MODEL_DIR/model.keras"
            if [ -f "$PERSISTENT_MODEL_DIR/labels.txt" ]; then
              cp "$PERSISTENT_MODEL_DIR/labels.txt" "$WORKSPACE_MODEL_DIR/labels.txt"
            fi
            echo "âœ… Model restored from persistent storage"
            ls -la "$WORKSPACE_MODEL_DIR"
          else
            echo "âš ï¸ No model found in persistent storage at $PERSISTENT_MODEL_DIR"
            echo "   Attempting to download from Azure ML..."

            # Fallback: download directly if persistent storage is empty
            MODEL_VERSION=$(az ml model list --name ${{ env.MODEL_NAME }} --query "[0].version" -o tsv 2>/dev/null || echo "")
            if [ -n "$MODEL_VERSION" ]; then
              TEMP_DIR="/tmp/model-fallback-$$"
              mkdir -p "$TEMP_DIR"
              az ml model download --name ${{ env.MODEL_NAME }} --version $MODEL_VERSION --download-path "$TEMP_DIR"

              MODEL_FILE=$(find "$TEMP_DIR" -name "model.keras" -type f | head -1)
              if [ -n "$MODEL_FILE" ]; then
                cp "$MODEL_FILE" "$WORKSPACE_MODEL_DIR/model.keras"
                mkdir -p "$PERSISTENT_MODEL_DIR"
                cp "$MODEL_FILE" "$PERSISTENT_MODEL_DIR/model.keras"
                echo "âœ… Model downloaded and stored"
              fi
              rm -rf "$TEMP_DIR"
            else
              echo "âŒ Could not find model in Azure ML"
              exit 1
            fi
          fi

      - name: Stop Existing Containers
        working-directory: sports-ball-classification/inference
        run: |
          echo "ğŸ›‘ Stopping existing containers..."
          docker-compose down 2>/dev/null || true
          echo "âœ… Containers stopped"

      - name: Build Docker Images
        working-directory: sports-ball-classification/inference
        run: |
          echo "ğŸ”¨ Building Docker images..."
          docker-compose build
          echo "âœ… Build complete"

      - name: Start Containers
        working-directory: sports-ball-classification/inference
        run: |
          echo "ğŸš€ Starting containers..."
          docker-compose up -d
          echo "âœ… Containers started"

      - name: Wait for Services
        run: |
          echo "â³ Waiting for services to start..."
          sleep 15

      - name: Health Check - API
        run: |
          echo "ğŸ¥ Running API health check..."
          for i in {1..12}; do
            if curl -s http://localhost:8000/health | grep -q "healthy"; then
              echo "âœ… API is healthy!"
              break
            fi
            echo "   Waiting for API... (attempt $i/12)"
            sleep 5
          done

      - name: Health Check - Dashboard
        run: |
          echo "ğŸ¥ Running Dashboard health check..."
          for i in {1..12}; do
            if curl -s http://localhost:8501/_stcore/health | grep -q "ok"; then
              echo "âœ… Dashboard is healthy!"
              break
            fi
            echo "   Waiting for Dashboard... (attempt $i/12)"
            sleep 5
          done

      - name: Test Prediction
        run: |
          echo "ğŸ§ª Testing prediction endpoint..."

          SAMPLE_IMAGE=$(find data -name "*.jpg" 2>/dev/null | head -1)
          if [ -n "$SAMPLE_IMAGE" ]; then
            echo "   Using sample image: $SAMPLE_IMAGE"
            RESULT=$(curl -s -X POST "http://localhost:8000/predict" \
              -H "accept: application/json" \
              -H "Content-Type: multipart/form-data" \
              -F "img=@$SAMPLE_IMAGE")
            echo "   Result: $RESULT"
          fi

      - name: Deployment Summary
        working-directory: sports-ball-classification/inference
        run: |
          echo ""
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘           ğŸ‰ Deployment Complete!                           â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ğŸ“¡ API Endpoints:"
          echo "   â€¢ Swagger UI: http://localhost:8000/docs"
          echo "   â€¢ Health:     http://localhost:8000/health"
          echo "   â€¢ Predict:    http://localhost:8000/predict"
          echo "   â€¢ Categories: http://localhost:8000/categories"
          echo "   â€¢ Stats:      http://localhost:8000/stats"
          echo ""
          echo "ğŸ”¥ Grad-CAM Dashboard:"
          echo "   â€¢ Dashboard:  http://localhost:8501"
          echo "   â€¢ Health:     http://localhost:8501/_stcore/health"
          echo ""
          echo "ğŸ“Š Container status:"
          docker-compose ps

  # ============================================================================
  # Cleanup Azure Resources
  # ============================================================================
  cleanup:
    name: ğŸ—‘ï¸ Cleanup Azure Resources
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.action == 'cleanup' }}

    steps:
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Delete Resource Group
        run: |
          echo "ğŸ—‘ï¸ Deleting resource group '${{ env.RESOURCE_GROUP }}'..."
          echo "âš ï¸ This will delete ALL resources in the group!"

          az group delete --name ${{ env.RESOURCE_GROUP }} --yes --no-wait

          echo "âœ… Deletion initiated (running in background)"

  # ============================================================================
  # Pipeline Summary
  # ============================================================================
  summary:
    name: ğŸ“‹ Pipeline Summary
    runs-on: ubuntu-latest
    needs:
      [
        configure-permissions,
        setup-azure,
        train-model,
        download-model,
        deploy-inference,
      ]
    if: always() && github.event.inputs.action != 'cleanup'

    steps:
      - name: Print Summary
        run: |
          echo ""
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘     ğŸ€ Sports Ball Classification - Pipeline Summary ğŸ€     â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ğŸ“Š Stage Results:"
          echo "   0ï¸âƒ£  Permissions:     ${{ needs.configure-permissions.result || 'skipped' }}"
          echo "   1ï¸âƒ£  Azure Setup:     ${{ needs.setup-azure.result || 'skipped' }}"
          echo "   2ï¸âƒ£  Model Training:  ${{ needs.train-model.result || 'skipped' }}"
          echo "   3ï¸âƒ£  Model Download:  ${{ needs.download-model.result || 'skipped' }}"
          echo "   4ï¸âƒ£  API Deployment:  ${{ needs.deploy-inference.result || 'skipped' }}"
          echo ""

          if [ "${{ needs.train-model.outputs.job_name }}" != "" ]; then
            echo "ğŸ”¬ Training Job: ${{ needs.train-model.outputs.job_name }}"
            echo ""
          fi

          echo "ğŸ”— Azure ML Studio: https://ml.azure.com"
          echo "ğŸ“¡ Local API: http://localhost:8000/docs"
          echo ""
